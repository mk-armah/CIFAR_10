{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06856e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler,Normalizer,MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7eae63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self,transform = None):\n",
    "        self.data = make_classification(n_samples=90000,n_features=5,n_classes=3,n_clusters_per_class=1,random_state=42)\n",
    "        self.features,self.classes =self.data\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        sample = self.features[index].reshape(-1,1),self.classes[index]\n",
    "        if self.transform:\n",
    "            return self.transform(sample)\n",
    "        else:\n",
    "            return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d4fe186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class transform(MinMaxScaler):\n",
    "    \"\"\"implement a custom Normalization using Min Max Scaler \"\"\"\n",
    "    \n",
    "    def __init__(self,ToTensor = False):\n",
    "        \"\"\"ToTensor >>>> Convert output samples to Tensors\"\"\"\n",
    "        \n",
    "        self.ToTensor = ToTensor\n",
    "        super(transform,self).__init__()\n",
    "        \n",
    "    def __call__(self,sample):\n",
    "        x,y = sample\n",
    "        x = super().fit_transform(x)\n",
    "        if self.ToTensor:\n",
    "            x = torch.from_numpy(x)\n",
    "            y = torch.tensor(y)\n",
    "            y = y.type(torch.int64) #cross entropy requires target to be in int64 format (long)\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db4fd513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.2873],\n",
       "         [0.2400],\n",
       "         [0.1653],\n",
       "         [1.0000]], dtype=torch.float64),\n",
       " tensor([2]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = transform(ToTensor=True)\n",
    "sample = dataset(scaler)\n",
    "sample[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1730edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset(transform = transform(ToTensor=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a45efc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of our training data :::  62999.99999999999\n",
      "len of our testing data :::  13500.0\n",
      "len of validation data :::  13500.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"70% percent of our data will be used for training, 15% for testing and the last 15% for validation\"\"\"\n",
    "\n",
    "\n",
    "print(\"len of our training data ::: \",(70/100)*len(data))\n",
    "print(\"len of our testing data ::: \",(15/100)*len(data))\n",
    "print(\"len of validation data ::: \",(15/100)*len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a6b5fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "indeces = np.arange(90000)\n",
    "np.random.shuffle(indeces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63661f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(data,batch_size = 64,sampler = torch.utils.data.SubsetRandomSampler(indeces[0:62999]),\n",
    "                                 shuffle = False)\n",
    "\n",
    "testing_dataloader = DataLoader(data,batch_size = 64,sampler = torch.utils.data.SubsetRandomSampler(indeces[62999:76499]),\n",
    "                               shuffle = False)\n",
    "\n",
    "validation_dataloader = DataLoader(data,batch_size=64,sampler = torch.utils.data.SubsetRandomSampler(indeces[76499::]),\n",
    "                                  shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "681a83e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 5, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(training_dataloader))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "082d1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier,self).__init__()\n",
    "        self.sequential = nn.Sequential(nn.Linear(5*1,200),nn.ReLU(inplace = True),nn.Linear(200,50),nn.ReLU(inplace = True),\n",
    "                     nn.Linear(50,3))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,5*1).type(torch.float)\n",
    "        x = self.sequential(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03e62e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available device :::: cpu\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = 0.01)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('available device :::: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81b2bd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model,dataloader,optimizer,loss_fn):\n",
    "    model.train()\n",
    "    for batch,(x,y) in enumerate(dataloader):\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        y_pred  = model(x)\n",
    "        loss = loss_fn(y_pred,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Training Completed\")\n",
    "\n",
    "def testing_and_validation_loop(model,dataloader,loss_fn,mode):\n",
    "    model.eval()\n",
    "    test_val_loss,accuracy = 0,0\n",
    "    with torch.no_grad():\n",
    "        for x,y in dataloader:\n",
    "            x,y = x.to(device),y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred,y)\n",
    "            test_val_loss+=loss\n",
    "            acc = (y_pred.argmax(1)==y).sum().item()\n",
    "            accuracy+= acc\n",
    "        accuracy/= len(dataloader.dataset)\n",
    "        test_val_loss/=len(dataloader)\n",
    "        print('{} Accuracy ::: {}   >>>>>   Loss  ::: {}'.format(mode,accuracy,test_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e28f09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training ...........................................0/50\n",
      "Training Completed\n",
      "Model Validation..........................................\n",
      "validation Accuracy ::: 0.11352222222222222   >>>>>   Loss  ::: 0.5645785331726074\n",
      "Model Testing\n",
      "testing Accuracy ::: 0.11425555555555555   >>>>>   Loss  ::: 0.5540823936462402\n",
      "Model Training ...........................................5/50\n",
      "Training Completed\n",
      "Model Validation..........................................\n",
      "validation Accuracy ::: 0.12223333333333333   >>>>>   Loss  ::: 0.44622355699539185\n",
      "Model Testing\n",
      "testing Accuracy ::: 0.12268888888888889   >>>>>   Loss  ::: 0.4358471930027008\n",
      "Model Training ...........................................10/50\n",
      "Training Completed\n",
      "Model Validation..........................................\n",
      "validation Accuracy ::: 0.12656666666666666   >>>>>   Loss  ::: 0.38925808668136597\n",
      "Model Testing\n",
      "testing Accuracy ::: 0.12675555555555557   >>>>>   Loss  ::: 0.3804127871990204\n",
      "Model Training ...........................................15/50\n",
      "Training Completed\n",
      "Model Validation..........................................\n",
      "validation Accuracy ::: 0.12737777777777778   >>>>>   Loss  ::: 0.3673833906650543\n",
      "Model Testing\n",
      "testing Accuracy ::: 0.1276   >>>>>   Loss  ::: 0.3601834774017334\n",
      "Model Training ...........................................20/50\n",
      "Training Completed\n",
      "Model Validation..........................................\n",
      "validation Accuracy ::: 0.12814444444444445   >>>>>   Loss  ::: 0.35781243443489075\n",
      "Model Testing\n",
      "testing Accuracy ::: 0.1283   >>>>>   Loss  ::: 0.3510763645172119\n",
      "Model Training ...........................................25/50\n",
      "Training Completed\n",
      "Model Validation..........................................\n",
      "validation Accuracy ::: 0.12767777777777778   >>>>>   Loss  ::: 0.35429495573043823\n",
      "Model Testing\n",
      "testing Accuracy ::: 0.12791111111111111   >>>>>   Loss  ::: 0.34849628806114197\n",
      "Model Training ...........................................30/50\n",
      "Training Completed\n",
      "Model Validation..........................................\n",
      "validation Accuracy ::: 0.12826666666666667   >>>>>   Loss  ::: 0.3511407971382141\n",
      "Model Testing\n",
      "testing Accuracy ::: 0.12827777777777777   >>>>>   Loss  ::: 0.3453965485095978\n",
      "Model Training ...........................................35/50\n",
      "Training Completed\n",
      "Model Validation..........................................\n",
      "validation Accuracy ::: 0.1280111111111111   >>>>>   Loss  ::: 0.3510471284389496\n",
      "Model Testing\n",
      "testing Accuracy ::: 0.12825555555555557   >>>>>   Loss  ::: 0.34514856338500977\n",
      "Model Training ...........................................40/50\n",
      "Training Completed\n",
      "Model Validation..........................................\n",
      "validation Accuracy ::: 0.12837777777777779   >>>>>   Loss  ::: 0.3498111963272095\n",
      "Model Testing\n",
      "testing Accuracy ::: 0.12866666666666668   >>>>>   Loss  ::: 0.34389540553092957\n",
      "Model Training ...........................................45/50\n",
      "Training Completed\n",
      "Model Validation..........................................\n",
      "validation Accuracy ::: 0.12774444444444444   >>>>>   Loss  ::: 0.3482879400253296\n",
      "Model Testing\n",
      "testing Accuracy ::: 0.12791111111111111   >>>>>   Loss  ::: 0.3449108600616455\n",
      "\t\t\t\t\t\tEpochs Completed..............................................\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "for epochs in range(num_epochs):\n",
    "    if epochs%5==0:\n",
    "        print(f\"Model Training ...........................................{epochs}/50\")\n",
    "        training_loop(model,training_dataloader,optimizer,loss_fn)\n",
    "        print('Model Validation..........................................')\n",
    "        testing_and_validation_loop(model,validation_dataloader,loss_fn,mode = 'validation')\n",
    "        print('Model Testing')\n",
    "        testing_and_validation_loop(model,testing_dataloader,loss_fn,mode = 'testing')\n",
    "print('\\t\\t\\t\\t\\t\\tEpochs Completed..............................................\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aba2a83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba85550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
